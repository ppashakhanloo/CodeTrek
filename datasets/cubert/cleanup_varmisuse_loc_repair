#!/usr/bin/env python3

import os
from tqdm import tqdm
import json
import shutil

if not os.path.isdir("py_files/train"):
  os.makedirs("py_files/train")
if not os.path.isdir("py_files/eval"):
  os.makedirs("py_files/eval")
if not os.path.isdir("py_files/dev"):
  os.makedirs("py_files/dev")

numtrain = 0
numeval = 0
numdev = 0

def get_file_loc(string_loc, string):
  row = 1
  col = 1
  visited_chars = 0
  for i, char in enumerate(string):
    if char == "\n":
      row += 1
      col = 1
    else:
      col += 1
    visited_chars += 1
    if visited_chars == string_loc:
      return row, col
  return 0, 0

def untokenize(tokens):
  source = ""
  indents = 0
  
  line_start = False
  for token in tokens:
    if "\\u\\u\\uINDENT\\u\\u\\u" in token:
      indents += 1
      continue
    elif "\\u\\u\\uDEDENT\\u\\u\\u" in token:
      indents -= 1
      continue
    elif "\\u\\u\\uNEWLINE\\u\\u\\u" in token or "\\u\\u\\uNL\\u\\u\\u" in token:
      line_start = True
      continue
    
    token_to_add = token.replace("^_", "").replace("_", " ").replace("\\u", "_")
 
    if line_start:
      source += "\n" + "\t" * indents + token_to_add
      line_start = False
    else:
      source += token_to_add
 
  source = source.replace("$$$", "").replace("$$", " ").replace("    ", "")
  return source 
    
def process_json_collection(filename: str, index: int, kind: str):
  with open(filename, 'r') as json_collection:
    json_data = json_collection.readlines()
    for json_str in tqdm(json_data):
      datadict = json.loads(json_str)
    
      function = list(datadict["function"])
      error_location = list(datadict["error_location_mask"]).index(1)

      function[error_location] = "#ERR#" + function[error_location]
      untokenized_function = untokenize(function)
      
      untokenized_error_location = 0
      if "#ERR#" in untokenized_function:
        untokenized_error_location = untokenized_function.index("#ERR#")
      untokenized_function = untokenized_function.replace("#ERR#", "")
      wrong_local_variable = "___NONE___"
      correct_local_variable = "___NONE___"

      prov = datadict["provenance"].split("`")
      if len(prov) >= 4:
        wrong_local_variable = prov[3]
        correct_local_variable = prov[1]
      
      savepath = "py_files/" + kind + "/file_" + str(index)
      if os.path.isdir(savepath):
        shutil.rmtree(savepath)
      os.makedirs(savepath)
      with open(savepath + "/source.py", "w") as srcfile:
        srcfile.write(untokenized_function)
      with open(savepath + "/misuse_info.txt", "w") as mfile:
        row, col = get_file_loc(untokenized_error_location, untokenized_function)
        mfile.write("error_char_number,error_row,error_col,wrong_variable,correct_variable,provenance"+"\n"+str(untokenized_error_location)+","+str(row)+","+str(col)+","+wrong_local_variable+","+correct_local_variable+","+datadict["provenance"]+"\n")
      index += 1
  return index
        
bench = []
with open('benchmark_gen_list', 'r') as blist:
    bench = [x.strip() for x in blist.readlines()]

for filename in bench:
  if filename.startswith("dev"):
    print("Processing " + filename)
    numdev = process_json_collection(filename, numdev, "dev")
    print("Number of dev programs processed till now:", numdev)
  if filename.startswith("train"):
    print("Processing " + filename)
    numtrain = process_json_collection(filename, numtrain, "train")
    print("Number of train programs processed till now:", numtrain)
  if filename.startswith("eval"):
    print("Processing " + filename)
    numeval = process_json_collection(filename, numeval, "eval")
    print("Number of eval programs processed till now:", numeval)
