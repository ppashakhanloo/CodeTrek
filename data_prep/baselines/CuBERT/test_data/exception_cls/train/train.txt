{"function": "def postOptions(self):\n        if self['in'] is None:\n            raise usage.UsageError(\"%s\\nYou must specify the input filename.\"\n                                   % self)\n        if self[\"typein\"] == \"guess\":\n            try:\n                self[\"typein\"] = sob.guessType(self[\"in\"])\n            except __HOLE__:\n                raise usage.UsageError(\"Could not guess type for '%s'\" %\n                                       self[\"typein\"])", "label": "KeyError", "info": "dataset/ETHPy150Open nlloyd/SubliminalCollaborator/libs/twisted/scripts/tapconvert.py/ConvertOptions.postOptions"}
{"function": "@register.filter\ndef djdiv(value, arg):\n    \"\"\"\n    Divide the value by the arg, using Python 3-style division that returns\n    floats. If bad values are passed in, return the empty string.\n    \"\"\"\n\n    try:\n        return value / arg\n    except (__HOLE__, TypeError):\n        try:\n            return value / arg\n        except Exception:\n            return ''", "label": "ValueError", "info": "dataset/ETHPy150Open pydanny/dj-stripe/djstripe/templatetags/djstripe_tags.py/djdiv"}
{"function": "def getNewId(self, objType):\n        try:\n            objType = self.remap[objType]\n        except __HOLE__:\n            pass\n        try:\n            id = self.ids[objType]\n            self.ids[objType] += 1\n            return id\n        except KeyError:\n            self.ids[objType] = self.beginId + 1\n            return self.beginId", "label": "KeyError", "info": "dataset/ETHPy150Open VisTrails/VisTrails/vistrails/db/versions/v0_9_1/domain/id_scope.py/IdScope.getNewId"}
{"function": "def updateBeginId(self, objType, beginId):\n        try:\n            objType = self.remap[objType]\n        except __HOLE__:\n            pass\n        try:\n            if self.ids[objType] <= beginId:\n                self.ids[objType] = beginId\n        except KeyError:\n            self.ids[objType] = beginId", "label": "KeyError", "info": "dataset/ETHPy150Open VisTrails/VisTrails/vistrails/db/versions/v0_9_1/domain/id_scope.py/IdScope.updateBeginId"}
{"function": "def setBeginId(self, objType, beginId):\n        try:\n            objType = self.remap[objType]\n        except __HOLE__:\n            pass\n        self.ids[objType] = beginId", "label": "KeyError", "info": "dataset/ETHPy150Open VisTrails/VisTrails/vistrails/db/versions/v0_9_1/domain/id_scope.py/IdScope.setBeginId"}
{"function": "def make_sure_path_exists(path):\n    logging.debug('Make sure {} exists'.format(path))\n    try:\n        os.makedirs(path)\n    except __HOLE__ as e:\n        if e.errno != errno.EEXIST:\n            return False\n    return True", "label": "OSError", "info": "dataset/ETHPy150Open eyadsibai/brute-force-plotter/brute_force_plotter/utils.py/make_sure_path_exists"}
{"function": "def unescape_html(text):\n    \"\"\"Created by Fredrik Lundh (http://effbot.org/zone/re-sub.htm#unescape-html)\"\"\"\n    def fixup(m):\n        text = m.group(0)\n        if text[:2] == \"&#\":\n            # character reference\n            try:\n                if text[:3] == \"&#x\":\n                    return unichr(int(text[3:-1], 16))\n                else:\n                    return unichr(int(text[2:-1]))\n            except __HOLE__:\n                pass\n        else:\n            # named entity\n            try:\n                text = unichr(htmlentitydefs.name2codepoint[text[1:-1]])\n            except KeyError:\n                pass\n        return text # leave as is\n    return re.sub(\"&#?\\w+;\", fixup, text)", "label": "ValueError", "info": "dataset/ETHPy150Open sajao/CrisisLex/src-collect/tweepy1/utils.py/unescape_html"}
{"function": "def import_simplejson():\n    try:\n        import simplejson as json\n    except ImportError:\n        try:\n            import json  # Python 2.6+\n        except ImportError:\n            try:\n                from django.utils import simplejson as json  # Google App Engine\n            except __HOLE__:\n                raise ImportError, \"Can't load a json library\"\n\n    return json", "label": "ImportError", "info": "dataset/ETHPy150Open sajao/CrisisLex/src-collect/tweepy1/utils.py/import_simplejson"}
{"function": "def _construct_ring(self, param, msg='Parameter must be a sequence of LinearRings or objects that can initialize to LinearRings'):\n        \"Helper routine for trying to construct a ring from the given parameter.\"\n        if isinstance(param, LinearRing): return param\n        try:\n            ring = LinearRing(param)\n            return ring\n        except __HOLE__:\n            raise TypeError(msg)", "label": "TypeError", "info": "dataset/ETHPy150Open AppScale/appscale/AppServer/lib/django-1.2/django/contrib/gis/geos/polygon.py/Polygon._construct_ring"}
{"function": "def notifyDone(self, relay):\n        \"\"\"A relaying SMTP client is disconnected.\n\n        unmark all pending messages under this relay's responsibility\n        as being relayed, and remove the relay.\n        \"\"\"\n        for message in self.manager.managed.get(relay, ()):\n            if self.manager.queue.noisy:\n                log.msg(\"Setting \" + message + \" waiting\")\n            self.manager.queue.setWaiting(message)\n        try:\n            del self.manager.managed[relay]\n        except __HOLE__:\n            pass\n        notifications = self._completionDeferreds\n        self._completionDeferreds = None\n        for d in notifications:\n            d.callback(None)", "label": "KeyError", "info": "dataset/ETHPy150Open kuri65536/python-for-android/python-modules/twisted/twisted/mail/relaymanager.py/_AttemptManager.notifyDone"}
{"function": "def notifyNoConnection(self, relay):\n        \"\"\"Relaying SMTP client couldn't connect.\n\n        Useful because it tells us our upstream server is unavailable.\n        \"\"\"\n        # Back off a bit\n        try:\n            msgs = self.manager.managed[relay]\n        except __HOLE__:\n            log.msg(\"notifyNoConnection passed unknown relay!\")\n            return\n\n        if self.manager.queue.noisy:\n            log.msg(\"Backing off on delivery of \" + str(msgs))\n        def setWaiting(queue, messages):\n            map(queue.setWaiting, messages)\n        from twisted.internet import reactor\n        reactor.callLater(30, setWaiting, self.manager.queue, msgs)\n        del self.manager.managed[relay]", "label": "KeyError", "info": "dataset/ETHPy150Open kuri65536/python-for-android/python-modules/twisted/twisted/mail/relaymanager.py/_AttemptManager.notifyNoConnection"}
{"function": "def markGood(self, mx):\n        \"\"\"Indicate a given mx host is back online.\n\n        @type mx: C{str}\n        @param mx: The hostname of the host which is up.\n        \"\"\"\n        try:\n            del self.badMXs[mx]\n        except __HOLE__:\n            pass", "label": "KeyError", "info": "dataset/ETHPy150Open kuri65536/python-for-android/python-modules/twisted/twisted/mail/relaymanager.py/MXCalculator.markGood"}
{"function": "def __init__(self, nagcat, conf):\n        BaseTest.__init__(self, conf)\n\n        self._nagcat = nagcat\n        self._test = conf.get('test', \"\")\n        self._description = conf.get('description', self._test)\n        self._documentation = conf.get('documentation', \"\")\n        self._investigation = conf.get('investigation', \"\")\n        self._priority = conf.get('priority', \"\")\n        self._url = conf.get('url', \"\")\n        self._subtests = {}\n\n        # Special little value!\n        # Mark this test as CRITICAL if it has been in WARNING\n        # for too long. A value of 0 disables this check.\n        self._warning_time_limit = util.Interval(\n                conf.get('warning_time_limit', 0))\n\n        # If self._documentation is a list convert it to a string\n        if isinstance(self._documentation, list):\n            self._documentation = \"\\n\".join(self._documentation)\n        if isinstance(self._investigation, list):\n            self._investigation = \"\\n\".join(self._documentation)\n\n        if self._priority:\n            self._priority = \"Priority: %s\\n\\n\" % self._priority\n\n        if conf['query.type'] == \"compound\":\n            self._compound = True\n            conf['query'].expand(recursive=False)\n            self._return = conf.get('query.return', None)\n\n            for name, qconf in conf['query'].iteritems():\n                if not isinstance(qconf, struct.Struct):\n                    continue\n\n                self._addDefaults(qconf)\n                self._subtests[name] = nagcat.new_query(qconf,\n                        qcls=query.FilteredQuery)\n                self.addDependency(self._subtests[name])\n\n            if not self._subtests:\n                raise errors.ConfigError(conf['query'],\n                        \"compound query must have a sub-query\")\n            if self._return or len(self._subtests) > 1:\n                if not self._return:\n                    raise errors.ConfigError(conf['query'],\n                            \"return statement is required\")\n\n                # Convert $(subquery) to data['subquery']\n                self._return = re.sub(\"\\\\$\\\\(([^\\\\)]+)\\\\)\",\n                        lambda m: \"data['%s']\" % m.group(1), self._return)\n\n                test_values = {'NOW': util.MathString('9999')}\n                for name in self._subtests:\n                    #XXX this test string isn't fool-proof but will mostly work\n                    test_values[name] = util.MathString('9999')\n\n                try:\n                    log.trace(\"Testing expr %r with data=%r\" %\n                            (self._return, test_values))\n                    eval(self._return, {'data': test_values})\n                except SyntaxError, ex:\n                    raise errors.ConfigError(conf['query'],\n                            \"Syntax error in return: %s\" % ex)\n                except __HOLE__, ex:\n                    raise errors.ConfigError(conf['query'],\n                            \"Unknown sub-query in return: %s\" % ex)\n        else:\n            self._compound = False\n            qconf = conf.get('query')\n            self._addDefaults(qconf)\n            self._subtests['query'] = nagcat.new_query(qconf,\n                    qcls=query.FilteredQuery)\n            self.addDependency(self._subtests['query'])\n\n        self._report_callbacks = []", "label": "KeyError", "info": "dataset/ETHPy150Open marineam/nagcat/python/nagcat/test.py/Test.__init__"}
{"function": "def read_content(self, stream=False):\n        db = get_blob_db()\n        try:\n            blob = db.get(self.blob_id, self._blobdb_bucket())\n        except (__HOLE__, NotFound, BadName):\n            raise AttachmentNotFound(self.name)\n\n        if stream:\n            return blob\n\n        with blob:\n            return blob.read()", "label": "KeyError", "info": "dataset/ETHPy150Open dimagi/commcare-hq/corehq/form_processor/models.py/AbstractAttachment.read_content"}
{"function": "def walkTroveSet(self, topTrove, ignoreMissing = True,\n                     withFiles=True, asTuple=True):\n        \"\"\"\n        Generator returns all of the troves included by topTrove, including\n        topTrove itself. It is a depth first search of strong refs. Punchouts\n        are taken into account.\n\n        @param asTuple: If True, (name, version, flavor) tuples are returned\n        instead of Trove objects. This can be much faster.\n        \"\"\"\n        def _collect(l, tup):\n            if tup[1] is None:\n                if trove.troveIsComponent(tup[0][0]):\n                    # don't bother looking for children of components\n                    tup[1] = []\n                else:\n                    l.append(tup)\n            else:\n                for t in tup[1]:\n                    _collect(l, t)\n\n        if asTuple and hasattr(self, 'getTroveTroves'):\n            assert(not withFiles)\n            seen = set()\n            all = [ topTrove.getNameVersionFlavor(), None ]\n            seen.add(topTrove.getNameVersionFlavor())\n            while True:\n                getList = []\n                _collect(getList, all)\n                if not getList:\n                    break\n\n                refs = self.getTroveTroves([ x[0] for x in getList],\n                                               justPresent = True)\n\n                for item, refList in itertools.izip(getList, refs):\n                    item[1] = []\n                    for x in refList:\n                        if x not in seen:\n                            seen.add(x)\n                            item[1].append([x, None])\n\n            stack = [ all ]\n            while stack:\n                next = stack.pop()\n                yield next[0]\n                stack += next[1]\n\n            return\n\n        def _format(trv):\n            if asTuple:\n                return trv.getNameVersionFlavor()\n            else:\n                return trv\n        yield _format(topTrove)\n        seen = { topTrove.getName() : [ (topTrove.getVersion(),\n                                         topTrove.getFlavor()) ] }\n\n        troveList = [x for x in sorted(topTrove.iterTroveList(strongRefs=True))]\n\n        while troveList:\n            (name, version, flavor) = troveList[0]\n            del troveList[0]\n\n            if seen.has_key(name):\n                match = False\n                for (ver, fla) in seen[name]:\n                    if version == ver and fla == flavor:\n                        match = True\n                        break\n                if match: continue\n\n                seen[name].append((version, flavor))\n            else:\n                seen[name] = [ (version, flavor) ]\n\n            try:\n                trv = self.getTrove(name, version, flavor, withFiles=withFiles)\n\n                yield _format(trv)\n\n                troveList = ([ x for x in\n                                sorted(trv.iterTroveList(strongRefs=True)) ]\n                              + troveList)\n            except errors.TroveMissing:\n                if not ignoreMissing:\n                    raise\n            except __HOLE__:\n                if not ignoreMissing:\n                    raise", "label": "KeyError", "info": "dataset/ETHPy150Open sassoftware/conary/conary/repository/trovesource.py/AbstractTroveSource.walkTroveSet"}
{"function": "def iterFilesInTrove(self, n, v, f, sortByPath=False, withFiles=False,\n                         capsules = False):\n        try:\n            cs = self.troveCsMap[n,v,f]\n        except __HOLE__:\n            raise errors.TroveMissing(n, v)\n\n        trvCs = cs.getNewTroveVersion(n,v,f)\n        fileList = trvCs.getNewFileList()\n        if not fileList:\n            return\n\n        if capsules:\n            fileList = [ x for x in fileList if x[0] == trove.CAPSULE_PATHID ]\n        else:\n            fileList = [ x for x in fileList if x[0] != trove.CAPSULE_PATHID ]\n\n        if not withFiles:\n            if sortByPath:\n                for item in sorted(fileList):\n                    yield item\n            else:\n                for item in fileList:\n                    yield item\n            return\n\n        if sortByPath:\n            # files stored in changesets are sorted by pathId, and must be\n            # retrieved in that order.  But we want to display them by\n            # path.  So, retrieve the info from the changeset by pathId\n            # and stored it in a dict to be retrieved after sorting by\n            # path\n            changes = {}\n            for pathId, path, fileId, version in fileList:\n                changes[pathId] = cs.getFileChange(None, fileId)\n\n            fileList = sorted(fileList, key=lambda x: x[1])\n\n        for pathId, path, fileId, version in fileList:\n            change = changes[pathId]\n            if change is None:\n                fileObj = None\n            else:\n                fileObj = files.ThawFile(change, pathId)\n            yield pathId, path, fileId, version, fileObj", "label": "KeyError", "info": "dataset/ETHPy150Open sassoftware/conary/conary/repository/trovesource.py/ChangesetFilesTroveSource.iterFilesInTrove"}
{"function": "def getTroves(self, troveList, withFiles = True, allowMissing=True,\n                    callback=None):\n        troveList = list(enumerate(troveList)) # make a copy and add indexes\n        numTroves = len(troveList)\n        results = [None] * numTroves\n\n        for source in self.sources:\n            newTroveList = []\n            newIndexes = []\n            try:\n                troves = source.getTroves([x[1] for x in troveList],\n                                          withFiles=withFiles,\n                                          callback=callback)\n            except __HOLE__:\n                continue\n            for ((index, troveTup), trove) in itertools.izip(troveList, troves):\n                if trove is None:\n                    newTroveList.append((index, troveTup))\n                else:\n                    results[index] = trove\n            troveList = newTroveList\n        if troveList and not allowMissing:\n            raise errors.TroveMissingError(troveList[0][1][0],\n                                           troveList[0][1][1])\n        return results", "label": "NotImplementedError", "info": "dataset/ETHPy150Open sassoftware/conary/conary/repository/trovesource.py/SourceStack.getTroves"}
{"function": "def getFileVersions(self, fileIds):\n        results = [ None ] * len(fileIds)\n        needed = list(enumerate(fileIds))\n        for source in self.sources:\n            try:\n                newResults = source.getFileVersions([ x[1] for x in needed ])\n                for result, (i, info) in itertools.izip(newResults, needed):\n                    if info:\n                        results[i] = result\n                needed = [ tup for tup in needed if results[tup[0]] is None ]\n                if not needed:\n                    break\n\n            # FIXME: there should be a better error for this\n            except (KeyError, __HOLE__), e:\n                continue\n\n        return results", "label": "NotImplementedError", "info": "dataset/ETHPy150Open sassoftware/conary/conary/repository/trovesource.py/SourceStack.getFileVersions"}
{"function": "def getFileVersion(self, pathId, fileId, version):\n        for source in self.sources:\n            try:\n                return source.getFileVersion(pathId, fileId, version)\n            # FIXME: there should be a better error for this\n            except (KeyError, __HOLE__), e:\n                continue\n        return None", "label": "NotImplementedError", "info": "dataset/ETHPy150Open sassoftware/conary/conary/repository/trovesource.py/SourceStack.getFileVersion"}
{"function": "def iterFilesInTrove(self, n, v, f, *args, **kw):\n        for source in self.sources:\n            try:\n                for value in source.iterFilesInTrove(n, v, f, *args, **kw):\n                    yield value\n                return\n            except __HOLE__:\n                pass\n            except errors.TroveMissing:\n                pass\n        raise errors.TroveMissing(n,v)", "label": "NotImplementedError", "info": "dataset/ETHPy150Open sassoftware/conary/conary/repository/trovesource.py/SourceStack.iterFilesInTrove"}
{"function": "def clever_reset_ref(git_project, ref, raises=True):\n    \"\"\" Resets only if needed, fetches only if needed \"\"\"\n    try:\n        remote_name = git_project.default_remote.name\n    except __HOLE__:\n        error_msg = \"Project {} has no default remote, defaulting to origin\"\n        ui.error(error_msg.format(git_project.name))\n        remote_name = \"origin\"\n\n    git = qisrc.git.Git(git_project.path)\n    if ref.startswith(\"refs/\"):\n        if raises:\n            git.fetch(remote_name, ref)\n            git.reset(\"--hard\", \"FETCH_HEAD\")\n            return\n        else:\n            with git.tansaction() as transaction:\n                git.fetch(remote_name, ref)\n                git.reset(\"--hard\", \"FETCH_HEAD\")\n                return transaction.ok, transaction.output\n\n    rc, ref_sha1 = git.call(\"rev-parse\", ref, raises=False)\n    if rc != 0:\n        # Maybe this is a newly pushed tag, try to fetch:\n        git.fetch(remote_name)\n        rc, ref_sha1 = git.call(\"rev-parse\", ref, raises=False)\n        if rc != 0:\n            return False, \"Could not parse %s as a valid ref\" % ref\n    _, actual_sha1 = git.call(\"rev-parse\", \"HEAD\", raises=False)\n    if actual_sha1 == ref_sha1:  # Nothing to do\n        if raises:\n            return\n        else:\n            return True, \"\"\n    ret, _ = git.call(\"show\", \"--oneline\", ref, raises=False)\n    if ret == 0:  # SHA-1 exists locally\n        if raises:\n            git.reset(\"--hard\", ref)\n        else:\n            rc, out = git.reset(\"--hard\", ref, raises=False)\n            return (rc == 0), out\n    else:  # Full fetch in this case\n        if raises:\n            git.fetch(remote_name)\n            git.reset(\"--hard\", ref)\n        else:\n            with git.transaction() as transaction:\n                git.fetch(remote_name)\n                git.reset(\"--hard\", ref)\n            return transaction.ok, transaction.output", "label": "AttributeError", "info": "dataset/ETHPy150Open aldebaran/qibuild/python/qisrc/reset.py/clever_reset_ref"}
{"function": "def _import_class_or_module(self, name):\n        \"\"\"\n        Import a class using its fully-qualified *name*.\n        \"\"\"\n        try:\n            path, base = self.py_sig_re.match(name).groups()\n        except:\n            raise ValueError(\n                \"Invalid class or module '%s' specified for inheritance diagram\" % name)\n        fullname = (path or '') + base\n        path = (path and path.rstrip('.'))\n        if not path:\n            path = base\n        try:\n            module = __import__(path, None, None, [])\n            # We must do an import of the fully qualified name.  Otherwise if a\n            # subpackage 'a.b' is requested where 'import a' does NOT provide\n            # 'a.b' automatically, then 'a.b' will not be found below.  This\n            # second call will force the equivalent of 'import a.b' to happen\n            # after the top-level import above.\n            my_import(fullname)\n            \n        except __HOLE__:\n            raise ValueError(\n                \"Could not import class or module '%s' specified for inheritance diagram\" % name)\n\n        try:\n            todoc = module\n            for comp in fullname.split('.')[1:]:\n                todoc = getattr(todoc, comp)\n        except AttributeError:\n            raise ValueError(\n                \"Could not find class or module '%s' specified for inheritance diagram\" % name)\n\n        # If a class, just return it\n        if inspect.isclass(todoc):\n            return [todoc]\n        elif inspect.ismodule(todoc):\n            classes = []\n            for cls in list(todoc.__dict__.values()):\n                if inspect.isclass(cls) and cls.__module__ == todoc.__name__:\n                    classes.append(cls)\n            return classes\n        raise ValueError(\n            \"'%s' does not resolve to a class or module\" % name)", "label": "ImportError", "info": "dataset/ETHPy150Open ipython/ipython-py3k/docs/sphinxext/inheritance_diagram.py/InheritanceGraph._import_class_or_module"}
{"function": "def run_dot(self, args, name, parts=0, urls={},\n                graph_options={}, node_options={}, edge_options={}):\n        \"\"\"\n        Run graphviz 'dot' over this graph, returning whatever 'dot'\n        writes to stdout.\n\n        *args* will be passed along as commandline arguments.\n\n        *name* is the name of the graph\n\n        *urls* is a dictionary mapping class names to http urls\n\n        Raises DotException for any of the many os and\n        installation-related errors that may occur.\n        \"\"\"\n        try:\n            dot = subprocess.Popen(['dot'] + list(args),\n                                   stdin=subprocess.PIPE, stdout=subprocess.PIPE,\n                                   close_fds=True)\n        except __HOLE__:\n            raise DotException(\"Could not execute 'dot'.  Are you sure you have 'graphviz' installed?\")\n        except ValueError:\n            raise DotException(\"'dot' called with invalid arguments\")\n        except:\n            raise DotException(\"Unexpected error calling 'dot'\")\n\n        self.generate_dot(dot.stdin, name, parts, urls, graph_options,\n                          node_options, edge_options)\n        dot.stdin.close()\n        result = dot.stdout.read()\n        returncode = dot.wait()\n        if returncode != 0:\n            raise DotException(\"'dot' returned the errorcode %d\" % returncode)\n        return result", "label": "OSError", "info": "dataset/ETHPy150Open ipython/ipython-py3k/docs/sphinxext/inheritance_diagram.py/InheritanceGraph.run_dot"}
{"function": "def _validate_volume(driver_info, volume_id):\n    \"\"\"Validates if volume is in Storage pools designated for ironic.\"\"\"\n\n    volume = _get_volume(driver_info, volume_id)\n\n    # Check if the ironic <scard>/ironic-<pool_id>/<volume_id> naming scheme\n    # is present in volume id\n    try:\n        pool_id = volume.id.split('/')[1].lower()\n    except __HOLE__:\n        pool_id = \"\"\n\n    if \"ironic-\" in pool_id:\n        return True\n    else:\n        raise exception.InvalidParameterValue(_(\n            \"Invalid volume id specified\"))", "label": "IndexError", "info": "dataset/ETHPy150Open openstack/ironic/ironic/drivers/modules/seamicro.py/_validate_volume"}
{"function": "@staticmethod\n    def eval_config_parameter(param):\n        \"\"\"\n        Try to evaluate the given parameter as a string or integer and return\n        it properly. This is used to parse i3status configuration parameters\n        such as 'disk \"/home\" {}' or worse like '\"cpu_temperature\" 0 {}'.\n        \"\"\"\n        params = param.split(' ')\n        result_list = list()\n\n        for p in params:\n            try:\n                e_value = eval(p)\n                if isinstance(e_value, str) or isinstance(e_value, int):\n                    p = str(e_value)\n                else:\n                    raise ValueError()\n            except (__HOLE__, SyntaxError, ValueError):\n                pass\n            finally:\n                result_list.append(p)\n\n        return ' '.join(result_list)", "label": "NameError", "info": "dataset/ETHPy150Open ultrabug/py3status/py3status/i3status.py/I3status.eval_config_parameter"}
{"function": "@staticmethod\n    def eval_config_value(value):\n        \"\"\"\n        Try to evaluate the given parameter as a string or integer and return\n        it properly. This is used to parse i3status configuration parameters\n        such as 'disk \"/home\" {}' or worse like '\"cpu_temperature\" 0 {}'.\n        \"\"\"\n        if value.lower() in ('true', 'false'):\n            return eval(value.title())\n        try:\n            e_value = eval(value)\n            if isinstance(e_value, str):\n                if e_value.lower() in ('true', 'false'):\n                    value = eval(e_value.title())\n                else:\n                    value = e_value\n            elif isinstance(e_value, int):\n                value = e_value\n            else:\n                raise ValueError()\n        except (NameError, __HOLE__):\n            pass\n        finally:\n            return value", "label": "ValueError", "info": "dataset/ETHPy150Open ultrabug/py3status/py3status/i3status.py/I3status.eval_config_value"}
{"function": "def i3status_config_reader(self, i3status_config_path):\n        \"\"\"\n        Parse i3status.conf so we can adapt our code to the i3status config.\n        \"\"\"\n        config = {\n            'general': {\n                'color_bad': '#FF0000',\n                'color_degraded': '#FFFF00',\n                'color_good': '#00FF00',\n                'color_separator': '#333333',\n                'colors': False,\n                'interval': 5,\n                'output_format': 'i3bar'\n            },\n            'i3s_modules': [],\n            'on_click': {},\n            'order': [],\n            '.group_extras': [],  # extra i3status modules needed by groups\n            '.module_groups': {},  # record groups that modules are in\n            'py3_modules': []\n        }\n\n        # some ugly parsing\n        in_section = False\n        section_name = ''\n        group_name = None\n\n        for line in open(i3status_config_path, 'r'):\n            line = line.strip(' \\t\\n\\r')\n\n            if not line or line.startswith('#'):\n                continue\n\n            if line.startswith('order'):\n                in_section = True\n                section_name = 'order'\n\n            if not in_section and line.startswith('group'):\n                group_name = line.split('{')[0].strip()\n                config[group_name] = {'items': []}\n                continue\n\n            if not in_section and group_name and line == '}':\n                group_name = None\n                continue\n\n            if group_name and not in_section and '=' in line:\n                # check this is not a section definition\n                if '{' not in line or line.index('{') > line.index('='):\n                    key = line.split('=', 1)[0].strip()\n                    key = self.eval_config_parameter(key)\n                    value = line.split('=', 1)[1].strip()\n                    value = self.eval_config_value(value)\n                    if not key.startswith('on_click'):\n                        config[group_name][key] = value\n                    else:\n                        # on_click special parameters\n                        try:\n                            button = int(key.split()[1])\n                            if button not in range(1, 6):\n                                raise ValueError('should be 1, 2, 3, 4 or 5')\n                        except IndexError as e:\n                            raise IndexError(\n                                'missing \"button id\" for \"on_click\" '\n                                'parameter in group {}'.format(group_name))\n                        except ValueError as e:\n                            raise ValueError('invalid \"button id\" '\n                                             'for \"on_click\" parameter '\n                                             'in group {} ({})'.format(\n                                                 group_name, e))\n                        on_c = config['on_click']\n                        on_c[group_name] = on_c.get(group_name, {})\n                        on_c[group_name][button] = value\n                    continue\n\n            if not in_section:\n                section_name = line.split('{')[0].strip()\n                section_name = self.eval_config_parameter(section_name)\n                if not section_name:\n                    continue\n                else:\n                    in_section = True\n                    if section_name not in config:\n                        config[section_name] = {}\n                    if group_name:\n                        # update the items in the group\n                        config[group_name]['items'].append(section_name)\n                        section = config['.module_groups'].setdefault(section_name, [])\n                        if group_name not in section:\n                            section.append(group_name)\n                        if not self.valid_config_param(section_name):\n                            # py3status module add a reference to the group and\n                            # make sure we have it in the list of modules to\n                            # run\n                            if section_name not in config['py3_modules']:\n                                config['py3_modules'].append(section_name)\n                        else:\n                            # i3status module.  Add to the list of needed\n                            # modules and add to the `.group-extras` config to\n                            # ensure that it gets run even though not in\n                            # `order` config\n                            if section_name not in config['i3s_modules']:\n                                config['i3s_modules'].append(section_name)\n                            if section_name not in config['.group_extras']:\n                                config['.group_extras'].append(section_name)\n\n            if '{' in line:\n                in_section = True\n\n            if section_name and '=' in line:\n                section_line = line\n\n                # one liner cases\n                if line.endswith('}'):\n                    section_line = section_line.split('}', -1)[0].strip()\n                if line.startswith(section_name + ' {'):\n                    section_line = section_line.split(section_name + ' {')[\n                        1].strip()\n\n                key = section_line.split('=', 1)[0].strip()\n                key = self.eval_config_parameter(key)\n\n                value = section_line.split('=', 1)[1].strip()\n                value = self.eval_config_value(value)\n\n                if section_name == 'order':\n                    config[section_name].append(value)\n                    line = '}'\n\n                    # create an empty config for this module\n                    if value not in config:\n                        config[value] = {}\n\n                    # detect internal modules to be loaded dynamically\n                    if not self.valid_config_param(value):\n                        config['py3_modules'].append(value)\n                    else:\n                        config['i3s_modules'].append(value)\n                else:\n                    if not key.startswith('on_click'):\n                        config[section_name][key] = value\n                    else:\n                        # on_click special parameters\n                        try:\n                            button = int(key.split()[1])\n                            if button not in range(1, 6):\n                                raise ValueError('should be 1, 2, 3, 4 or 5')\n                        except IndexError as e:\n                            raise IndexError(\n                                'missing \"button id\" for \"on_click\" '\n                                'parameter in section {}'.format(section_name))\n                        except __HOLE__ as e:\n                            raise ValueError('invalid \"button id\" '\n                                             'for \"on_click\" parameter '\n                                             'in section {} ({})'.format(\n                                                 section_name, e))\n                        on_c = config['on_click']\n                        on_c[section_name] = on_c.get(section_name, {})\n                        on_c[section_name][button] = value\n\n            if line.endswith('}'):\n                in_section = False\n                section_name = ''\n\n        # py3status only uses the i3bar protocol because it needs JSON output\n        if config['general']['output_format'] != 'i3bar':\n            raise RuntimeError('i3status output_format should be set' +\n                               ' to \"i3bar\" on {}'.format(\n                                   i3status_config_path,\n                                   ' or on your own {}/.i3status.conf'.format(\n                                       os.path.expanduser(\n                                           '~')) if i3status_config_path ==\n                                   '/etc/i3status.conf' else ''))\n\n        # time and tztime modules need a format for correct processing\n        for name in config:\n            if name.split()[0] in TIME_MODULES and 'format' not in config[\n                    name]:\n                if name.split()[0] == 'time':\n                    config[name]['format'] = TIME_FORMAT\n                else:\n                    config[name]['format'] = TZTIME_FORMAT\n\n        def clean_i3status_modules(key):\n            # cleanup unconfigured i3status modules that have no default\n            for module_name in deepcopy(config[key]):\n                if (self.valid_config_param(module_name,\n                                            cleanup=True) and\n                        not config.get(module_name)):\n                    config.pop(module_name)\n                    if module_name in config['i3s_modules']:\n                        config['i3s_modules'].remove(module_name)\n                    config[key].remove(module_name)\n\n        clean_i3status_modules('order')\n        clean_i3status_modules('.group_extras')\n        return config", "label": "ValueError", "info": "dataset/ETHPy150Open ultrabug/py3status/py3status/i3status.py/I3status.i3status_config_reader"}
{"function": "@staticmethod\n    def write_in_tmpfile(text, tmpfile):\n        \"\"\"\n        Write the given text in the given tmpfile in python2 and python3.\n        \"\"\"\n        try:\n            tmpfile.write(text)\n        except __HOLE__:\n            tmpfile.write(str.encode(text))", "label": "TypeError", "info": "dataset/ETHPy150Open ultrabug/py3status/py3status/i3status.py/I3status.write_in_tmpfile"}
{"function": "@profile\n    def run(self):\n        \"\"\"\n        Spawn i3status using a self generated config file and poll its output.\n        \"\"\"\n        try:\n            with NamedTemporaryFile(prefix='py3status_') as tmpfile:\n                self.write_tmp_i3status_config(tmpfile)\n                syslog(LOG_INFO,\n                       'i3status spawned using config file {}'.format(\n                           tmpfile.name))\n\n                i3status_pipe = Popen(\n                    ['i3status', '-c', tmpfile.name],\n                    stdout=PIPE,\n                    stderr=PIPE,\n                    # Ignore the SIGUSR2 signal for this subprocess\n                    preexec_fn=lambda:  signal(SIGUSR2, SIG_IGN)\n                )\n                self.poller_inp = IOPoller(i3status_pipe.stdout)\n                self.poller_err = IOPoller(i3status_pipe.stderr)\n                self.tmpfile_path = tmpfile.name\n\n                # Store the pipe so we can signal it\n                self.i3status_pipe = i3status_pipe\n\n                try:\n                    # loop on i3status output\n                    while self.lock.is_set():\n                        line = self.poller_inp.readline()\n                        if line:\n                            # remove leading comma if present\n                            if line[0] == ',':\n                                line = line[1:]\n                            if line.startswith('[{'):\n                                json_list = loads(line)\n                                self.last_output = json_list\n                                self.set_responses(json_list)\n                                self.ready = True\n                        else:\n                            err = self.poller_err.readline()\n                            code = i3status_pipe.poll()\n                            if code is not None:\n                                msg = 'i3status died'\n                                if err:\n                                    msg += ' and said: {}'.format(err)\n                                else:\n                                    msg += ' with code {}'.format(code)\n                                raise IOError(msg)\n                except IOError:\n                    err = sys.exc_info()[1]\n                    self.error = err\n        except __HOLE__:\n            # we cleanup the tmpfile ourselves so when the delete will occur\n            # it will usually raise an OSError: No such file or directory\n            pass\n        self.i3status_pipe = None", "label": "OSError", "info": "dataset/ETHPy150Open ultrabug/py3status/py3status/i3status.py/I3status.run"}
{"function": "def _do_action(self, action, path, *args, **kwargs):\n        \"\"\"Call **action** on each filesystem object in turn. If one raises an\n        :py:class:`IOError`, save the exception and try the rest. If none\n        succeed, re-raise the first exception.\n        \"\"\"\n\n        first_exception = None\n\n        for fs in self.filesystems:\n            if fs.can_handle_path(path):\n                try:\n                    return getattr(fs, action)(path, *args, **kwargs)\n                except __HOLE__ as e:\n                    if first_exception is None:\n                        first_exception = e\n\n        if first_exception is None:\n            raise IOError(\"Can't handle path: %s\" % path)\n        else:\n            raise first_exception", "label": "IOError", "info": "dataset/ETHPy150Open Yelp/mrjob/mrjob/fs/composite.py/CompositeFilesystem._do_action"}
{"function": "def ensure_exists(path):\n    try: \n        os.makedirs(path)\n    except __HOLE__ as e:\n        if e.errno == errno.EEXIST: # (path exists)\n            pass\n        if not os.path.isdir(path):\n            raise", "label": "OSError", "info": "dataset/ETHPy150Open memex-explorer/memex-explorer/source/apps/crawl_space/utils.py/ensure_exists"}
{"function": "def rm_if_exists(filename):\n    try:\n        os.remove(filename)\n        return True\n    except __HOLE__ as e:\n        if e.errno != errno.ENOENT: # (no such file or directory)\n            raise\n        return False", "label": "OSError", "info": "dataset/ETHPy150Open memex-explorer/memex-explorer/source/apps/crawl_space/utils.py/rm_if_exists"}
{"function": "def parse_provider_config(type, config):\n    try:\n        instance = manager.get(type)\n    except KeyError:\n        raise ApiError(\n            message='Invalid provider: {}'.format(type),\n            name='invalid_provider',\n        )\n\n    result = {}\n    all_options = chain(instance.get_default_options().items(),\n                        instance.get_options().items())\n    for option, option_values in all_options:\n        value = config.get(option)\n        if value and option_values.get('type'):\n            try:\n                config[option] = option_values['type'](value)\n            except (__HOLE__, TypeError):\n                raise ApiError(\n                    message='Option \"{}\" is not a valid type for provider: {}'.format(option, type),\n                    name='invalid_check',\n                )\n        if option_values.get('required') and not value:\n            raise ApiError(\n                message='Missing required option \"{}\" for provider: {}'.format(option, type),\n                name='invalid_provider',\n            )\n        result[option] = value\n    return result", "label": "ValueError", "info": "dataset/ETHPy150Open getsentry/freight/freight/providers/utils.py/parse_provider_config"}
{"function": "def absent(name):\n    '''\n    Ensures that the user does not exist, eventually delete user.\n\n    .. versionadded:: 2016.3.0\n\n    :param name: user alias\n    :param _connection_user: Optional - zabbix user (can also be set in opts or pillar, see module's docstring)\n    :param _connection_password: Optional - zabbix password (can also be set in opts or pillar, see module's docstring)\n    :param _connection_url: Optional - url of zabbix frontend (can also be set in opts, pillar, see module's docstring)\n\n    .. code-block:: yaml\n\n        George:\n            zabbix_user.absent\n\n    '''\n    ret = {'name': name, 'changes': {}, 'result': False, 'comment': ''}\n\n    # Comment and change messages\n    comment_user_deleted = 'USer {0} deleted.'.format(name)\n    comment_user_notdeleted = 'Unable to delete user: {0}. '.format(name)\n    comment_user_notexists = 'User {0} does not exist.'.format(name)\n    changes_user_deleted = {name: {'old': 'User {0} exists.'.format(name),\n                                   'new': 'User {0} deleted.'.format(name),\n                                   }\n                            }\n\n    user_get = __salt__['zabbix.user_get'](name)\n\n    # Dry run, test=true mode\n    if __opts__['test']:\n        if not user_get:\n            ret['result'] = True\n            ret['comment'] = comment_user_notexists\n        else:\n            ret['result'] = None\n            ret['comment'] = comment_user_deleted\n            ret['changes'] = changes_user_deleted\n\n    if not user_get:\n        ret['result'] = True\n        ret['comment'] = comment_user_notexists\n    else:\n        try:\n            userid = user_get[0]['userid']\n            user_delete = __salt__['zabbix.user_delete'](userid)\n        except __HOLE__:\n            user_delete = False\n\n        if user_delete and 'error' not in user_delete:\n            ret['result'] = True\n            ret['comment'] = comment_user_deleted\n            ret['changes'] = changes_user_deleted\n        else:\n            ret['result'] = False\n            ret['comment'] = comment_user_notdeleted + str(user_delete['error'])\n\n    return ret", "label": "KeyError", "info": "dataset/ETHPy150Open saltstack/salt/salt/states/zabbix_user.py/absent"}
{"function": "def _iso_to_datetime(self, isodate):\n        date_formats = ('%Y-%m-%dT%H:%M:%SZ', '%Y-%m-%dT%H:%M:%S%z')\n        date = None\n\n        for date_format in date_formats:\n            try:\n                date = datetime.strptime(isodate, date_format)\n            except __HOLE__:\n                pass\n\n            if date:\n                break\n\n        return date", "label": "ValueError", "info": "dataset/ETHPy150Open apache/libcloud/libcloud/loadbalancer/drivers/rackspace.py/RackspaceLBDriver._iso_to_datetime"}
{"function": "def _plot_labels(target, *labels):\n    for l in labels:\n        have_label = False\n        for child in target.get_children():\n            try:\n                if child.get_text() == l['s'] and child.get_position() == (l['x'], l['y']):\n                    have_label = True\n                    break\n            except __HOLE__:\n                pass\n        if not have_label:\n            target.text(**l)", "label": "AttributeError", "info": "dataset/ETHPy150Open scot-dev/scot/scot/plotting.py/_plot_labels"}
{"function": "def __call__(self, environ, start_response):\n        url = []\n\n        def change_response(status, headers, exc_info=None):\n            status_code = status.split(' ')\n            try:\n                code = int(status_code[0])\n            except (ValueError, __HOLE__):\n                raise Exception(\n                    'StatusBasedForward middleware '\n                    'received an invalid status code %s'%repr(status_code[0])\n                )\n            message = ' '.join(status_code[1:])\n            new_url = self.mapper(\n                code,\n                message,\n                environ,\n                self.global_conf,\n                **self.params\n            )\n            if not (new_url == None or isinstance(new_url, str)):\n                raise TypeError(\n                    'Expected the url to internally '\n                    'redirect to in the StatusBasedForward mapper'\n                    'to be a string or None, not %r' % new_url)\n            if new_url:\n                url.append([new_url, status, headers])\n                # We have to allow the app to write stuff, even though\n                # we'll ignore it:\n                return [].append\n            else:\n                return start_response(status, headers, exc_info)\n\n        app_iter = self.application(environ, change_response)\n        if url:\n            if hasattr(app_iter, 'close'):\n                app_iter.close()\n\n            def factory(app):\n                return StatusKeeper(app, status=url[0][1], url=url[0][0],\n                                    headers=url[0][2])\n            raise ForwardRequestException(factory=factory)\n        else:\n            return app_iter", "label": "TypeError", "info": "dataset/ETHPy150Open cloudera/hue/desktop/core/ext-py/Paste-2.0.1/paste/errordocument.py/StatusBasedForward.__call__"}
{"function": "def make_errordocument(app, global_conf, **kw):\n    \"\"\"\n    Paste Deploy entry point to create a error document wrapper.\n\n    Use like::\n\n        [filter-app:main]\n        use = egg:Paste#errordocument\n        next = real-app\n        500 = /lib/msg/500.html\n        404 = /lib/msg/404.html\n    \"\"\"\n    map = {}\n    for status, redir_loc in kw.items():\n        try:\n            status = int(status)\n        except __HOLE__:\n            raise ValueError('Bad status code: %r' % status)\n        map[status] = redir_loc\n    forwarder = forward(app, map)\n    return forwarder", "label": "ValueError", "info": "dataset/ETHPy150Open cloudera/hue/desktop/core/ext-py/Paste-2.0.1/paste/errordocument.py/make_errordocument"}
{"function": "def __call__(self, environ, start_response):\n        url = []\n        code_message = []\n        try:\n            def change_response(status, headers, exc_info=None):\n                new_url = None\n                parts = status.split(' ')\n                try:\n                    code = int(parts[0])\n                except (ValueError, __HOLE__):\n                    raise Exception(\n                        '_StatusBasedRedirect middleware '\n                        'received an invalid status code %s'%repr(parts[0])\n                    )\n                message = ' '.join(parts[1:])\n                new_url = self.mapper(\n                    code,\n                    message,\n                    environ,\n                    self.global_conf,\n                    self.kw\n                )\n                if not (new_url == None or isinstance(new_url, str)):\n                    raise TypeError(\n                        'Expected the url to internally '\n                        'redirect to in the _StatusBasedRedirect error_mapper'\n                        'to be a string or None, not %s'%repr(new_url)\n                    )\n                if new_url:\n                    url.append(new_url)\n                code_message.append([code, message])\n                return start_response(status, headers, exc_info)\n            app_iter = self.application(environ, change_response)\n        except:\n            try:\n                import sys\n                error = str(sys.exc_info()[1])\n            except:\n                error = ''\n            try:\n                code, message = code_message[0]\n            except:\n                code, message = ['', '']\n            environ['wsgi.errors'].write(\n                'Error occurred in _StatusBasedRedirect '\n                'intercepting the response: '+str(error)\n            )\n            return [self.fallback_template\n                    % {'message': message, 'code': code}]\n        else:\n            if url:\n                url_ = url[0]\n                new_environ = {}\n                for k, v in environ.items():\n                    if k != 'QUERY_STRING':\n                        new_environ['QUERY_STRING'] = urlparse.urlparse(url_)[4]\n                    else:\n                        new_environ[k] = v\n                class InvalidForward(Exception):\n                    pass\n                def eat_start_response(status, headers, exc_info=None):\n                    \"\"\"\n                    We don't want start_response to do anything since it\n                    has already been called\n                    \"\"\"\n                    if status[:3] != '200':\n                        raise InvalidForward(\n                            \"The URL %s to internally forward \"\n                            \"to in order to create an error document did not \"\n                            \"return a '200' status code.\" % url_\n                        )\n                forward = environ['paste.recursive.forward']\n                old_start_response = forward.start_response\n                forward.start_response = eat_start_response\n                try:\n                    app_iter = forward(url_, new_environ)\n                except InvalidForward:\n                    code, message = code_message[0]\n                    environ['wsgi.errors'].write(\n                        'Error occurred in '\n                        '_StatusBasedRedirect redirecting '\n                        'to new URL: '+str(url[0])\n                    )\n                    return [\n                        self.fallback_template%{\n                            'message':message,\n                            'code':code,\n                        }\n                    ]\n                else:\n                    forward.start_response = old_start_response\n                    return app_iter\n            else:\n                return app_iter", "label": "TypeError", "info": "dataset/ETHPy150Open cloudera/hue/desktop/core/ext-py/Paste-2.0.1/paste/errordocument.py/_StatusBasedRedirect.__call__"}
{"function": "def _run_policies(self, envelope):\n        results = [envelope]\n\n        def recurse(current, i):\n            try:\n                policy = self.queue_policies[i]\n            except __HOLE__:\n                return\n            ret = policy.apply(current)\n            if ret:\n                results.remove(current)\n                results.extend(ret)\n                for env in ret:\n                    recurse(env, i+1)\n            else:\n                recurse(current, i+1)\n        recurse(envelope, 0)\n        return results", "label": "IndexError", "info": "dataset/ETHPy150Open slimta/python-slimta/slimta/queue/__init__.py/Queue._run_policies"}
{"function": "def _dequeue(self, id):\n        try:\n            envelope, attempts = self.store.get(id)\n        except __HOLE__:\n            return\n        if id not in self.active_ids:\n            self.active_ids.add(id)\n            self._pool_spawn('relay', self._attempt, id, envelope, attempts)", "label": "KeyError", "info": "dataset/ETHPy150Open slimta/python-slimta/slimta/queue/__init__.py/Queue._dequeue"}
{"function": "def _wait_store(self):\n        while True:\n            try:\n                for entry in self.store.wait():\n                    self._add_queued(entry)\n            except __HOLE__:\n                return", "label": "NotImplementedError", "info": "dataset/ETHPy150Open slimta/python-slimta/slimta/queue/__init__.py/Queue._wait_store"}
{"function": "def _wait_ready(self, now):\n        try:\n            first = self.queued[0]\n        except __HOLE__:\n            self.wake.wait()\n            self.wake.clear()\n            return\n        first_timestamp = first[0]\n        if first_timestamp > now:\n            self.wake.wait(first_timestamp-now)\n            self.wake.clear()", "label": "IndexError", "info": "dataset/ETHPy150Open slimta/python-slimta/slimta/queue/__init__.py/Queue._wait_ready"}
{"function": "def parse_argspec(obj_or_str):\n    if isinstance(obj_or_str, basestring):\n        obj_or_str = obj_or_str.strip()\n        if not obj_or_str.endswith(\":\"):\n            obj_or_str += \":\"\n        if not obj_or_str.startswith(\"def \"):\n            obj_or_str = \"def \" + obj_or_str\n        try:\n            tree = ast.parse(obj_or_str + \"\\n  pass\")\n        except SyntaxError:\n            # cannot parse the argspec\n            print \"*** CANNOT PARSE\", obj_or_str\n            return []\n        argspec_name = tree.body[0].name\n        argspec_args = [a.id for a in tree.body[0].args.args]\n        print tree.body[0].args.defaults\n        argspec_defaults = []\n        for i, d in enumerate(tree.body[0].args.defaults):\n            try:\n                d_val = ast.literal_eval(d)\n            except __HOLE__:\n                d_val = None\n            argspec_defaults.append(d_val)\n    else:\n        argspec = inspect.getargspec(obj_or_str)\n        argspec_args = argspec.args\n        argspec_defaults = argspec.defaults\n\n    if not argspec_defaults:\n        start_defaults = len(argspec_args) + 1\n    else:\n        start_defaults = len(argspec_args) - len(argspec_defaults)\n    port_specs_list = []\n    has_self = False\n    for i, arg in enumerate(argspec_args):\n        if i == 0 and arg == \"self\":\n            has_self = True\n            continue\n        port_spec = InputPortSpec(arg)\n        port_spec.arg_pos = (i-1) if has_self else i\n        if i >= start_defaults:\n            port_spec.required = False\n            default_val = argspec_defaults[i-start_defaults]\n            if default_val is not None:\n                port_spec.defaults = [default_val]\n                port_type = get_type_from_val(default_val)\n                if port_type is not None:\n                    port_spec.port_type = port_type\n        else:\n            port_spec.required = True\n        port_specs_list.append(port_spec)\n    return port_specs_list", "label": "ValueError", "info": "dataset/ETHPy150Open VisTrails/VisTrails/vistrails/packages/matplotlib/parse.py/parse_argspec"}
{"function": "def parse_plots(plot_types, table_overrides):\n    def get_module_base(n):\n        return n\n    def get_super_base(n):\n        return \"plot\"\n\n    module_specs = []\n    for plot in plot_types:\n        port_specs = {}\n        print \"========================================\"\n        print plot\n        print \"========================================\"\n        \n        (plot, module_name, super_name) = \\\n            get_names(plot, get_module_base, get_super_base, \"Mpl\", \"\")\n\n        try:\n            plot_obj = getattr(matplotlib.pyplot, plot)\n        except __HOLE__:\n            print '*** CANNOT ADD PLOT \"%s\";' \\\n                'IT DOES NOT EXIST IN THIS MPL VERSION ***' % plot\n            continue\n        \n        port_specs_list = parse_argspec(plot_obj)\n        for port_spec in port_specs_list:\n            port_specs[port_spec.arg] = port_spec\n\n        docstring = plot_obj.__doc__\n        if plot == 'contour':\n            # want to change the double newline to single newline...\n            print \"&*&* FINDING:\", \\\n                docstring.find(\"*extent*: [ *None* | (x0,x1,y0,y1) ]\\n\\n\")\n            docstring = docstring.replace(\"*extent*: [ *None* | (x0,x1,y0,y1) ]\\n\\n\", \n                              \"*extent*: [ *None* | (x0,x1,y0,y1) ]\\n\")\n        if plot == 'annotate':\n            docstring = docstring % dict((k,v) for k, v in matplotlib.docstring.interpd.params.iteritems() if k == 'Annotation')\n        elif plot == 'barbs':\n            docstring = docstring % dict((k,v) for k,v in matplotlib.docstring.interpd.params.iteritems() if k == 'barbs_doc')\n\n        cleaned_docstring, output_port_specs = \\\n            process_docstring(docstring, port_specs, ('pyplot', plot),\n                              table_overrides)\n\n        # for port_spec in port_specs.itervalues():\n        #     if port_spec.defaults is not None:\n        #         port_spec.defaults = [str(v) for v in port_spec.defaults]\n        #     if port_spec.values is not None:\n        #         port_spec.values = [[str(v) for v in port_spec.values[0]]]\n        #     for alt_ps in port_spec.alternate_specs:\n        #         if alt_ps.defaults is not None:\n        #             alt_ps.defaults = [str(v) for v in alt_ps.defaults]\n        #         if alt_ps.values is not None:\n        #             alt_ps.values = [[str(v) for v in alt_ps.values[0]]]\n                \n        module_specs.append(ModuleSpec(module_name, super_name,\n                                       \"matplotlib.pyplot.%s\" % plot, \n                                       cleaned_docstring, port_specs.values(),\n                                       output_port_specs))\n    my_specs = SpecList(module_specs)\n    return my_specs", "label": "AttributeError", "info": "dataset/ETHPy150Open VisTrails/VisTrails/vistrails/packages/matplotlib/parse.py/parse_plots"}
{"function": "def info(name):\n    '''\n    Return information about a group\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' group.info foo\n    '''\n    try:\n        grinfo = grp.getgrnam(name)\n    except __HOLE__:\n        return {}\n    else:\n        return _format_info(grinfo)", "label": "KeyError", "info": "dataset/ETHPy150Open saltstack/salt/salt/modules/groupadd.py/info"}
{"function": "def get_related_tags(self, request, **kwargs):\n        \"\"\" Can be used to get all tags used by all CommitteeMeetings of a specific committee\n        \"\"\"\n        try:\n            ctype = ContentType.objects.get_by_natural_key(kwargs['app_label'], kwargs['object_type'])\n        except ContentType.DoesNotExist:\n            raise Http404('Object type not found.')\n\n        model = ctype.model_class()\n        container = get_object_or_404(model, pk=kwargs['object_id'])\n        try:\n            related_objects = getattr(container, kwargs['related_name']).all()\n        except __HOLE__:\n            raise Http404('Related name not found.')\n\n        tags = Tag.objects.usage_for_queryset(related_objects)\n\n        return self._create_response(request, tags)", "label": "AttributeError", "info": "dataset/ETHPy150Open ofri/Open-Knesset/auxiliary/api.py/TagResource.get_related_tags"}
{"function": "def _plot_sources_raw(ica, raw, picks, exclude, start, stop, show, title,\n                      block):\n    \"\"\"Function for plotting the ICA components as raw array.\"\"\"\n    color = _handle_default('color', (0., 0., 0.))\n    orig_data = ica._transform_raw(raw, 0, len(raw.times)) * 0.2\n    if picks is None:\n        picks = range(len(orig_data))\n    types = ['misc' for _ in picks]\n    picks = list(sorted(picks))\n    eog_chs = pick_types(raw.info, meg=False, eog=True, ref_meg=False)\n    ecg_chs = pick_types(raw.info, meg=False, ecg=True, ref_meg=False)\n    data = [orig_data[pick] for pick in picks]\n    c_names = ['ICA %03d' % x for x in range(len(orig_data))]\n    for eog_idx in eog_chs:\n        c_names.append(raw.ch_names[eog_idx])\n        types.append('eog')\n    for ecg_idx in ecg_chs:\n        c_names.append(raw.ch_names[ecg_idx])\n        types.append('ecg')\n    extra_picks = np.append(eog_chs, ecg_chs).astype(int)\n    if len(extra_picks) > 0:\n        eog_ecg_data, _ = raw[extra_picks, :]\n        for idx in range(len(eog_ecg_data)):\n            if idx < len(eog_chs):\n                eog_ecg_data[idx] /= 150e-6  # scaling for eog\n            else:\n                eog_ecg_data[idx] /= 5e-4  # scaling for ecg\n        data = np.append(data, eog_ecg_data, axis=0)\n\n    for idx in range(len(extra_picks)):\n        picks = np.append(picks, ica.n_components_ + idx)\n    if title is None:\n        title = 'ICA components'\n    info = create_info([c_names[x] for x in picks], raw.info['sfreq'])\n\n    info['bads'] = [c_names[x] for x in exclude]\n    if start is None:\n        start = 0\n    if stop is None:\n        stop = start + 20\n        stop = min(stop, raw.times[-1])\n    duration = stop - start\n    if duration <= 0:\n        raise RuntimeError('Stop must be larger than start.')\n    t_end = int(duration * raw.info['sfreq'])\n    times = raw.times[0:t_end]\n    bad_color = (1., 0., 0.)\n    inds = list(range(len(picks)))\n    data = np.array(data)\n    n_channels = min([20, len(picks)])\n    params = dict(raw=raw, orig_data=data, data=data[:, 0:t_end],\n                  ch_start=0, t_start=start, info=info, duration=duration,\n                  ica=ica, n_channels=n_channels, times=times, types=types,\n                  n_times=raw.n_times, bad_color=bad_color, picks=picks)\n    _prepare_mne_browse_raw(params, title, 'w', color, bad_color, inds,\n                            n_channels)\n    params['scale_factor'] = 1.0\n    params['plot_fun'] = partial(_plot_raw_traces, params=params, inds=inds,\n                                 color=color, bad_color=bad_color)\n    params['update_fun'] = partial(_update_data, params)\n    params['pick_bads_fun'] = partial(_pick_bads, params=params)\n    params['label_click_fun'] = partial(_label_clicked, params=params)\n    _layout_figure(params)\n    # callbacks\n    callback_key = partial(_plot_raw_onkey, params=params)\n    params['fig'].canvas.mpl_connect('key_press_event', callback_key)\n    callback_scroll = partial(_plot_raw_onscroll, params=params)\n    params['fig'].canvas.mpl_connect('scroll_event', callback_scroll)\n    callback_pick = partial(_mouse_click, params=params)\n    params['fig'].canvas.mpl_connect('button_press_event', callback_pick)\n    callback_resize = partial(_helper_raw_resize, params=params)\n    params['fig'].canvas.mpl_connect('resize_event', callback_resize)\n    callback_close = partial(_close_event, params=params)\n    params['fig'].canvas.mpl_connect('close_event', callback_close)\n    params['fig_proj'] = None\n    params['event_times'] = None\n    params['update_fun']()\n    params['plot_fun']()\n    try:\n        plt_show(show, block=block)\n    except __HOLE__:  # not all versions have this\n        plt_show(show)\n    return params['fig']", "label": "TypeError", "info": "dataset/ETHPy150Open mne-tools/mne-python/mne/viz/ica.py/_plot_sources_raw"}
{"function": "def _plot_sources_epochs(ica, epochs, picks, exclude, start, stop, show,\n                         title, block):\n    \"\"\"Function for plotting the components as epochs.\"\"\"\n    data = ica._transform_epochs(epochs, concatenate=True)\n    eog_chs = pick_types(epochs.info, meg=False, eog=True, ref_meg=False)\n    ecg_chs = pick_types(epochs.info, meg=False, ecg=True, ref_meg=False)\n    c_names = ['ICA %03d' % x for x in range(ica.n_components_)]\n    ch_types = np.repeat('misc', ica.n_components_)\n    for eog_idx in eog_chs:\n        c_names.append(epochs.ch_names[eog_idx])\n        ch_types = np.append(ch_types, 'eog')\n    for ecg_idx in ecg_chs:\n        c_names.append(epochs.ch_names[ecg_idx])\n        ch_types = np.append(ch_types, 'ecg')\n    extra_picks = np.append(eog_chs, ecg_chs).astype(int)\n    if len(extra_picks) > 0:\n        eog_ecg_data = np.concatenate(epochs.get_data()[:, extra_picks],\n                                      axis=1)\n        data = np.append(data, eog_ecg_data, axis=0)\n    scalings = _handle_default('scalings_plot_raw')\n    scalings['misc'] = 5.0\n    info = create_info(ch_names=c_names, sfreq=epochs.info['sfreq'],\n                       ch_types=ch_types)\n    info['projs'] = list()\n    info['bads'] = [c_names[x] for x in exclude]\n    if title is None:\n        title = 'ICA components'\n    if picks is None:\n        picks = list(range(ica.n_components_))\n    if start is None:\n        start = 0\n    if stop is None:\n        stop = start + 20\n        stop = min(stop, len(epochs.events))\n    for idx in range(len(extra_picks)):\n        picks = np.append(picks, ica.n_components_ + idx)\n    n_epochs = stop - start\n    if n_epochs <= 0:\n        raise RuntimeError('Stop must be larger than start.')\n    params = {'ica': ica,\n              'epochs': epochs,\n              'info': info,\n              'orig_data': data,\n              'bads': list(),\n              'bad_color': (1., 0., 0.),\n              't_start': start * len(epochs.times)}\n    params['label_click_fun'] = partial(_label_clicked, params=params)\n    _prepare_mne_browse_epochs(params, projs=list(), n_channels=20,\n                               n_epochs=n_epochs, scalings=scalings,\n                               title=title, picks=picks,\n                               order=['misc', 'eog', 'ecg'])\n    params['plot_update_proj_callback'] = _update_epoch_data\n    _update_epoch_data(params)\n    params['hsel_patch'].set_x(params['t_start'])\n    callback_close = partial(_close_epochs_event, params=params)\n    params['fig'].canvas.mpl_connect('close_event', callback_close)\n    try:\n        plt_show(show, block=block)\n    except __HOLE__:  # not all versions have this\n        plt_show(show)\n    return params['fig']", "label": "TypeError", "info": "dataset/ETHPy150Open mne-tools/mne-python/mne/viz/ica.py/_plot_sources_epochs"}
{"function": "def list_projects(folders, folder = None, user = None):\n    '''List all folders or all subfolders of a folder.\n\n    If folder is provided, this method will output a list of subfolders\n    contained by it.  Otherwise, a list of all top-level folders is produced.\n\n    :param folders: reference to folder.Folders instance\n    :param folder: folder name or None\n    :param user: optional user name\n\n    '''\n    fid = None if folder is None else Folders.name_to_id(folder)\n\n    # List all folders if none provided.\n    if fid is None:\n        for f in folders.folders(user):\n            print(Folders.id_to_name(f))\n\n        return\n\n    # List subfolders of a specific folder\n    try:\n        for sid in folders.subfolders(fid, user):\n            print(Folders.id_to_name(sid))\n    except __HOLE__:\n        print(\"E: folder not found: %s\" %folder, file=sys.stderr)", "label": "KeyError", "info": "dataset/ETHPy150Open dossier/dossier.models/dossier/models/query.py/list_projects"}
{"function": "def run(hide=False, more=False, start=\"01-01-2012\", end=None):\n    \"\"\"Update local game data.\"\"\"\n    # get today's information\n    year = date.today().year\n    month = date.today().month\n    day = date.today().day\n    # get ending date information\n    if end != None:\n        end_month, end_day, end_year = end.split(\"-\")\n        end_month, end_day, end_year = [int(end_month), int(end_day), int(end_year)]\n    else:\n        end_year = year\n        end_month = month\n        end_day = day\n    # get starting date information\n    start_month, start_day, start_year = start.split(\"-\")\n    first_day, first_month, last_month = [True, True, False]\n    # print a message becuase sometimes it seems like the program is not doing anything\n    if not hide:\n        print(\"Checking local data...\")\n    # looping years\n    for i in range(int(start_year), end_year+1):\n        # checking if starting month value needs to be used\n        if first_month:\n            ms = int(start_month)\n            first_month = False\n        else:\n            ms = 1\n        # looping months\n        me = 13\n        if i == end_year:\n            me = end_month+1\n            last_month = True\n        for x in range(ms, me):\n            monthstr = str(x).zfill(2)\n            loading = False\n            if i == year and x > month:\n                break\n            # checking if starting day value needs to be used\n            if first_day:\n                ds = int(start_day)\n                first_day = False\n            else:\n                ds = 1\n            # looping days\n            de = 32\n            if last_month:\n                de = end_day+1\n            for y in range(ds, de):\n                if i == year and x >= month and y >= day:\n                    break\n                daystr = str(y).zfill(2)\n                # file information\n                filename = \"gameday-data/year_%i/month_%s/day_%s/scoreboard.xml.gz\" % (i, monthstr, daystr)\n                f = os.path.join(os.path.dirname(os.path.abspath(__file__)), filename)\n                dirn = \"gameday-data/year_%i/month_%s/day_%s\" % (i, monthstr, daystr)\n                dirname = os.path.join(os.path.dirname(os.path.abspath(__file__)), dirn)\n                # check if file exists\n                # aka is the data saved\n                if not os.path.isfile(f):\n                    # try becuase some dates may not have a file on the mlb.com server\n                    # or some months don't have a 31st day\n                    try:\n                        # get data from url\n                        data = urlopen(\"http://gd2.mlb.com/components/game/mlb/year_%i/month_%s/day_%s/scoreboard.xml\" % (i, monthstr, daystr))\n                        # loding bar to show something is actually happening\n                        if not hide:\n                            sys.stdout.write('Loading games for %s-%d (%00.2f%%) \\r' % (monthstr, i, y/31.0*100))\n                            sys.stdout.flush()\n                        loading = True\n                        response = data.read()\n                        # check if the path exists where the file should go\n                        if not os.path.exists(dirname):\n                            try:\n                                # try to make the folder if permissions allow\n                                os.makedirs(dirname)\n                            except OSError:\n                                access_error(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'gameday-data/'))\n                        try:\n                            # try to create the file if permissions allow\n                            with gzip.open(f, \"w\") as fi:\n                                fi.write(response)\n                        except OSError:\n                            access_error(dirname)\n                    # do nothing if the file is not on mlb.com\n                    except HTTPError:\n                        pass\n                # get extra data if specified\n                if more:\n                    try:\n                        # get the data for games on this day\n                        games = mlbgame.day(i, x, y)\n                        for z in games:\n                            # get the game id which is used to fetch data\n                            game_id = z.game_id\n                            # file information\n                            filename2 = \"gameday-data/year_%i/month_%s/day_%s/gid_%s/boxscore.xml.gz\" % (i, monthstr, daystr, game_id)\n                            f2 = os.path.join(os.path.dirname(os.path.abspath(__file__)), filename2)\n                            dirn2 = \"gameday-data/year_%i/month_%s/day_%s/gid_%s\" % (i, monthstr, daystr, game_id)\n                            dirname2 = os.path.join(os.path.dirname(os.path.abspath(__file__)), dirn2)\n                            # check if file exists\n                            # aka is the information saved\n                            if not os.path.isfile(f2):\n                                # try becuase some dates may not have a file on the mlb.com server\n                                # or some months don't have a 31st day\n                                try:\n                                    # get data\n                                    data2 = urlopen(\"http://gd2.mlb.com/components/game/mlb/year_%i/month_%s/day_%s/gid_%s/boxscore.xml\" % (i, monthstr, daystr, game_id))\n                                    if not hide:\n                                        # progress\n                                        sys.stdout.write('Loading games for %s-%d (%00.2f%%). \\r' % (monthstr, i, y/31.0*100))\n                                        sys.stdout.flush()\n                                    loading = True\n                                    response2 = data2.read()\n                                    # checking if files exist and writing new files\n                                    if not os.path.exists(dirname2):\n                                        try:\n                                            os.makedirs(dirname2)\n                                        except OSError:\n                                            access_error(os.path.join(os.path.dirname(os.path.abspath(__file__)), 'gameday-data/'))\n                                    # try to write file\n                                    try:\n                                        with gzip.open(f2, \"w\") as fi:\n                                            fi.write(response2)\n                                    except __HOLE__:\n                                        access_error(dirname2)\n                                except HTTPError:\n                                    pass\n                    except:\n                        pass\n            if loading and not hide:\n                # make sure loading ends at 100%\n                sys.stdout.write('Loading games for %s-%d (100.00%%).\\n' % (monthstr, i))\n                sys.stdout.flush()\n    # print finished message\n    if not hide:\n        print(\"Complete.\")", "label": "OSError", "info": "dataset/ETHPy150Open zachpanz88/mlbgame/mlbgame/update.py/run"}
{"function": "def _yaml_include(self, loader, node):\n        \"\"\"\n        Include another yaml file from main file\n        This is usually done by registering !include tag\n        \"\"\"\n        filepath = node.value\n        if not os.path.exists(filepath):\n            for dir in self.conf_dirs:\n                filepath = os.path.join(dir, node.value)\n                if os.path.exists(filepath):\n                    break\n\n        self.conf_dirs.append(os.path.dirname(filepath))\n        try:\n            with open(filepath, 'r') as inputfile:\n                return yaml.load(inputfile)\n        except __HOLE__ as e:\n            lg.error(\"Can't include config file %s: %s\" % (filepath, e))\n            raise", "label": "IOError", "info": "dataset/ETHPy150Open gooddata/smoker/smoker/server/daemon.py/Smokerd._yaml_include"}
{"function": "def _load_config(self):\n        \"\"\"\n        Load specified config file\n        \"\"\"\n        try:\n            with open(self.conf['config'], 'r') as fp:\n                config = fp.read()\n        except __HOLE__ as e:\n            lg.error(\"Can't read config file %s: %s\" % (self.conf['config'], e))\n            raise\n\n        # Register include constructors\n        yaml.add_constructor('!include_dir', self._yaml_include_dir)\n        yaml.add_constructor('!include', self._yaml_include)\n\n        try:\n            conf = yaml.load(config)\n        except Exception as e:\n            lg.error(\"Can't parse config file %s: %s\" % (self.conf['config'], e))\n            raise\n        finally:\n            fp.close()\n\n        # Store parameters but don't overwite\n        # those submitted by command line\n        for key, value in conf.iteritems():\n            if self.conf.has_key(key):\n                # User has submitted own parameter,\n                # use that instead of config one\n                lg.debug(\"Using parameter %s from user, ignoring config file value\" % key)\n            else:\n                self.conf[key] = value", "label": "IOError", "info": "dataset/ETHPy150Open gooddata/smoker/smoker/server/daemon.py/Smokerd._load_config"}
{"function": "def run(self):\n        \"\"\"\n        Run daemon\n         * change effective uid/gid\n         * start thread for each check\n         * start webserver\n        \"\"\"\n        lg.info(\"Starting daemon\")\n\n        # Change effective UID/GID\n        if self.conf.has_key('uid') and self.conf.has_key('gid'):\n            if os.geteuid != self.conf['uid'] and os.getegid != self.conf['gid']:\n                try:\n                    os.setegid(self.conf['gid'])\n                    os.seteuid(self.conf['uid'])\n                except TypeError as e:\n                    lg.error(\"Config parameters uid/gid have to be integers: %s\" % e)\n                except OSError as e:\n                    lg.error(\"Can't switch effective UID/GID to %s/%s: %s\" % (self.conf['uid'], self.conf['gid'], e))\n                    lg.exception(e)\n                    self._shutdown(exitcode=1)\n        else:\n            lg.info(\"Not changing effective UID/GID, keeping %s/%s\" % (os.geteuid(), os.getegid()))\n\n        if not isinstance(self.conf['bind_port'], int):\n            lg.error(\"Config parameter bind_port has to be integer\")\n\n        # Initialize plugin manager\n        config = {}\n\n        for key in ['plugins', 'templates', 'actions']:\n            try:\n                config[key] = self.conf[key]\n            except __HOLE__ as e:\n                lg.warn(\"Config section not found: %s\" % e)\n\n        # Check we have some plugins configured\n        if not config['plugins']:\n            lg.error('No configured plugins')\n            self._shutdown(exitcode=1)\n\n        if 'nr_concurrent_plugins' in self.conf:\n            config['semaphore_count'] = self.conf['nr_concurrent_plugins']\n\n        try:\n            self.pluginmgr = PluginManager(**config)\n        except Exception as e:\n            lg.error(\"Can't initialize PluginManager\")\n            lg.exception(e)\n            self._shutdown(exitcode=1)\n\n        lg.info(\"Starting webserver on %(bind_host)s:%(bind_port)s\"\n                % self.conf)\n        try:\n            self.server = RestServer(self.conf['bind_host'],\n                                     self.conf['bind_port'], self)\n            self.server.start()\n        except Exception as e:\n            lg.error(\"Can't start HTTP server: %s\" % e)\n            lg.exception(e)\n            self._shutdown(exitcode=1)\n\n        # Catch SIGINT and SIGTERM if supported\n        if hasattr(signal, 'SIGINT'):\n            signal.signal(signal.SIGINT, self._shutdown)\n\n        if hasattr(signal, 'SIGTERM'):\n            signal.signal(signal.SIGTERM, self._shutdown)\n\n        if hasattr(signal, 'SIGHUP'):\n            signal.signal(signal.SIGHUP, self._reopen_logfiles)\n\n        self._watchdog()", "label": "KeyError", "info": "dataset/ETHPy150Open gooddata/smoker/smoker/server/daemon.py/Smokerd.run"}
{"function": "def validate_start_time(value):\n    try:\n        datetime.strptime(value, '%d.%m.%Y %H:%M')\n    except __HOLE__:\n        raise DjangoValidationError(_('Invalid input.'))", "label": "ValueError", "info": "dataset/ETHPy150Open OpenSlides/OpenSlides/openslides/agenda/signals.py/validate_start_time"}
{"function": "def __getattr__(self, key): \n        try: return self[key]\n        except __HOLE__, k: return None", "label": "KeyError", "info": "dataset/ETHPy150Open limodou/uliweb/uliweb/utils/storage.py/Storage.__getattr__"}
{"function": "def __delattr__(self, key):\n        try: del self[key]\n        except __HOLE__, k: raise AttributeError, k", "label": "KeyError", "info": "dataset/ETHPy150Open limodou/uliweb/uliweb/utils/storage.py/Storage.__delattr__"}
